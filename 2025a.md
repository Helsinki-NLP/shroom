---
title: The *SHROOM Shared Task Series
description: Hallucinations and Related Observable Overgenerations
layout: default
---

### Welcome to CHOMPS 2025 Shared Task — SHROOM-CAP, the Shared-task on Hallucinations and Related Observable Overgeneration Mistakes in Crosslingual Analyses of Publications 

<!-- TM: somehow jrvc elected to add a white-on-white title?
### <span style="color: white;"> Welcome to CHOMPS 2025 Shared Task — SHROOM-CAP, the Shared-task on Hallucinations and Related Observable Overgeneration Mistakes in Crosslingual Analyses of Publications </span> 
-->

<img style="width:45%" src="assets/img/shroom-cap.png" alt="Mu-SHROOM" title="Mu-SHROOM logo" align="right">

Welcome to the official shared task website for SHROOM-CAP, a [CHOMPS 2025](https://chomps2025.github.io/) shared task!

SHROOM-CAP stands for "**S**hared-task on **H**allucinations and **R**elated **O**bservable **O**vergeneration **M**istakes in **C**rosslingual **A**nalyses of **P**ublications".
SHROOM-CAP will invite participants to detect hallucination in the outputs of LLMs in a scientific context. 
This shared task builds upon our previous iteration, SHROOM, with a few key changes: 
- We're looking at high-resource languages such as, English, Spanish, French, Hindi and suprisal low-level languages;
- We focus on LLM outputs;
- Participants will have to detect if hallucination occurs or not.

_The information on this website is subject to change._ 
We send announcements for any major update on the [Google group mailing list](https://groups.google.com/g/shroomcap).

#### What is SHROOM-CAP?
The task consists in detecting precense of scientific hallucinations. 
Participants are asked to determine if a given scientific text produced by LLMs constitute hallucinations.
The task is held in cross-lingual setting, i.e., we provide data in multiple mixed languages and produced by a variety of public-weights LLMs.´

In practice, we provide an LLM output (as a string of characters, a list of tokens, and a list of logits), and participants have to predict if the LLM output string contains a hallucination (binary classification).

Participants are free to use any approach they deem appropriate, including using external resources, and work on any subset of languages they are interested in.

#### How will participants be evaluated?
TBA

#### Participant info
To participate, you need to register : [https://forms.gle/hWR9jwTBjZQmFKAE7](https://forms.gle/hWR9jwTBjZQmFKAE7)


#### Data
TBA



#### Important dates

This information is subject to change.
- TBA
- CHOMPS workshop: 23/24 December 2025 (co-located with AACL 2025)


#### Organizers of the shared task

- [Aman Sinha](https://amansinha09.github.io/),
Université de Lorraine, France
- [Raúl Vázquez](https://jrvc.github.io/), 
University of Helsinki, Finland
- [Timothee Mickus](https://timotheemickus.github.io/), 
University of Helsinki, Finland



#### Looking for something else?

The websites for all the iterations of the shared task are available here: 
- [Mu-SHROOM: Semeval-2025 Task3](./2025.md)
- [SHROOM: Semeval-2024 Task 6](./2024.md).
 


